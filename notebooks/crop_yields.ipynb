{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c04dfbd",
   "metadata": {},
   "source": [
    "# CROP YIELD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e360f95",
   "metadata": {},
   "source": [
    "## First I will combine all crop yield data into one DataFrame (yield_df) and import that table into Postgres to filter across all 7 data sets. Then I will pull those SQL queries back here to make visualizations.\n",
    "- This can all be done in Python but I want to practice more SQL and get used to how SQL and Python connect to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2930e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import requests as re\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e52b45",
   "metadata": {},
   "source": [
    "## Import multiple CSVs and concate into one DataFrame:\n",
    "https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a0c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r'C:\\Users\\Jasmine\\Documents\\NSS\\Projects\\AgAidFromAbroad\\data_yields' # use your path\n",
    "# all_files = glob.glob(os.path.join(path, \"*.csv\")) # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "# df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "# yield_df   = pd.concat(df_from_each_file, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f15f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all files imported into one\n",
    "# yield_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it to the same folder\n",
    "# yield_df.to_csv(r'C:\\Users\\Jasmine\\Documents\\NSS\\Projects\\AgAidFromAbroad\\data_yields\\yield_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d522aa",
   "metadata": {},
   "source": [
    "I will analyze this master crop yield CSV in SQL and replicate the queries to below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bbdf6f",
   "metadata": {},
   "source": [
    "## Which states request the most H-2A workers? How does this compare to states with the highest crop yields?\n",
    "For each crop:\n",
    "1. Get states with most workers\n",
    "2. Get states with most yields\n",
    "3. Change state names in 2 to match the two-letter abbreviations in 1\n",
    "4. INNER JOIN these two DataFrames together because I only want states that have both H-2A workers and recorded yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SQL connection\n",
    "database_name = 'ag_aid'\n",
    "connection_string = f\"postgresql://postgres:postgres@localhost:5432/{database_name}\"\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a48bd6a",
   "metadata": {},
   "source": [
    "### States with most citrus H-2A workers vs states with most citrus yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc63140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States with most workers\n",
    "query_cit1 = '''\n",
    "SELECT DISTINCT employer_state,\n",
    "   SUM((workers_req::float)) OVER(PARTITION BY employer_state)\n",
    "FROM main\n",
    "WHERE job_title ILIKE '%%citrus%%'\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_cit1)\n",
    "cit_wkr_states = pd.read_sql(query_cit1, con = engine)\n",
    "cit_wkr_states.rename(columns={'employer_state': 'state'}, inplace=True)\n",
    "cit_wkr_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd9e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States with most yields\n",
    "query_cit2 = '''\n",
    "SELECT DISTINCT state,\n",
    "    SUM(value) OVER(PARTITION BY state)\n",
    "FROM cy\n",
    "WHERE commodity LIKE 'CITRUS'\n",
    "GROUP BY state, value\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_cit2)\n",
    "cit_yld_states = pd.read_sql(query_cit2, con = engine)\n",
    "\n",
    "# States with most yields: Change states to two-letter abbreviations\n",
    "cit_yld_states['state'] = cit_yld_states['state'].map({'CALIFORNIA':'CA', 'FLORIDA':'FL', 'TEXAS':'TX', 'ARIZONA':'AZ'})\n",
    "cit_yld_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffbd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join (sum_x is workers, sum_y is yield)\n",
    "cit_merged = pd.merge(cit_wkr_states, cit_yld_states, on='state', how='inner')\n",
    "cit_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b48e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(cit_merged.sum_x, cit_merged.sum_y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1223a3ec",
   "metadata": {},
   "source": [
    "### States with most strawberry H-2A workers vs states with most strawberry yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec02a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States with most workers\n",
    "query_straw1 = '''\n",
    "SELECT DISTINCT employer_state,\n",
    "   SUM((workers_req::float)) OVER(PARTITION BY employer_state)\n",
    "FROM main\n",
    "WHERE job_title ILIKE '%%strawberr%%'\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_straw1)\n",
    "straw_wkr_states = pd.read_sql(query_straw1, con = engine)\n",
    "straw_wkr_states.rename(columns={'employer_state': 'state'}, inplace=True)\n",
    "straw_wkr_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States with most yields\n",
    "query_straw2 = '''\n",
    "SELECT DISTINCT state,\n",
    "    SUM(value) OVER(PARTITION BY state)\n",
    "FROM cy\n",
    "WHERE commodity LIKE 'STRAWBERRIES'\n",
    "GROUP BY state, value\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_straw2)\n",
    "straw_yld_states = pd.read_sql(query_straw2, con = engine)\n",
    "straw_yld_states\n",
    "\n",
    "# States with most yields: Change states to two-letter abbreviations\n",
    "straw_yld_states['state'] = straw_yld_states['state'].map({'CALIFORNIA':'CA', 'FLORIDA':'FL', 'OREGON':'OR', 'NORTH CAROLINA':'NC', 'WASHINGTON':'WA', 'MICHIGAN':'MI', 'NEW YORK':'NY', 'WISCONSIN':'WI', 'OHIO':'OH', 'PENNSYLVANIA':'PA'})\n",
    "straw_yld_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb890e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join (sum_x is workers, sum_y is yield)\n",
    "straw_merged = pd.merge(straw_wkr_states, straw_yld_states, on='state', how='inner')\n",
    "straw_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6797334",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(straw_merged.sum_x, straw_merged.sum_y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d554bc",
   "metadata": {},
   "source": [
    "### States with most sheep H-2A workers vs states with most sheep yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05290547",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# States with most workers\n",
    "query_she1 = '''\n",
    "SELECT DISTINCT employer_state,\n",
    "   SUM((workers_req::float)) OVER(PARTITION BY employer_state)\n",
    "FROM main\n",
    "WHERE job_title ILIKE '%%sheep%%'\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_she1)\n",
    "she_wkr_states = pd.read_sql(query_she1, con = engine)\n",
    "she_wkr_states.rename(columns={'employer_state': 'state'}, inplace=True)\n",
    "she_wkr_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17591bff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# States with most yields\n",
    "query_she2 = '''\n",
    "SELECT DISTINCT state,\n",
    "    SUM(value) OVER(PARTITION BY state)\n",
    "FROM cy\n",
    "WHERE commodity LIKE 'SHEEP'\n",
    "GROUP BY state, value\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_she2)\n",
    "she_yld_states = pd.read_sql(query_she2, con = engine)\n",
    "she_yld_states\n",
    "\n",
    "# States with most yields: Change states to two-letter abbreviations\n",
    "she_yld_states['state'] = she_yld_states['state'].map({'TEXAS':'TX', 'MONTANA':'MT', 'CALIFORNIA':'CA', 'WYOMING':'WY', 'IDAHO':'ID', 'IOWA':'IA', 'OREGON':'OR', 'COLORADO':'CO', 'SOUTH DAKOTA':'SD', 'UTAH':'UT', 'OHIO':'OH', 'OTHER STATES':'OTHER', 'MISSOURI':'MO', 'MINNESOTA':'MN', 'WISCONSIN':'WI', 'PENNSYLVANIA':'PA', 'NORTH DAKOTA':'ND', 'NEW YORK':'NY', 'ILLINOIS':'IL', 'MICHIGAN':'MI', 'VIRGINIA':'VA', 'ARIZONA':'AZ', 'WASHINGTON':'WA', 'NEBRASKA':'NE', 'NEW MEXICO':'NM', 'NEVADA':'NV', 'KENTUCKY':'KY', 'TENNESSEE':'TN', 'INDIANA':'IN', 'OKLAHOMA':'OK', 'KANSAS':'KS', 'WEST VIRGINIA':'WV', 'NORTH CAROLINA':'NC'})\n",
    "she_yld_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15018529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inner join (sum_x is workers, sum_y is yield)\n",
    "she_merged = pd.merge(she_wkr_states, she_yld_states, on='state', how='inner')\n",
    "she_merged = she_merged.rename(columns={'sum_x': 'Workers', 'sum_y': 'Yield'})\n",
    "she_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddfec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(she_merged.Workers, she_merged.Yield);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021505ad",
   "metadata": {},
   "source": [
    "### States with most lettuce H-2A workers vs states with most lettuce yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706a565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States with most workers\n",
    "query_let1 = '''\n",
    "SELECT DISTINCT employer_state,\n",
    "   SUM((workers_req::float)) OVER(PARTITION BY employer_state)\n",
    "FROM main\n",
    "WHERE job_title ILIKE '%%lettuce%%'\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_let1)\n",
    "let_wkr_states = pd.read_sql(query_let1, con = engine)\n",
    "let_wkr_states.rename(columns={'employer_state': 'state'}, inplace=True)\n",
    "let_wkr_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4449668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States with most yields\n",
    "query_let2 = '''\n",
    "SELECT DISTINCT state,\n",
    "    SUM(value) OVER(PARTITION BY state)\n",
    "FROM cy\n",
    "WHERE commodity LIKE 'LETTUCE'\n",
    "GROUP BY state, value\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_let2)\n",
    "let_yld_states = pd.read_sql(query_let2, con = engine)\n",
    "let_yld_states['state'] = let_yld_states['state'].map({'CALIFORNIA':'CA', 'ARIZONA':'AZ'})\n",
    "let_yld_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join (sum_x is workers, sum_y is yield)\n",
    "let_merged = pd.merge(let_wkr_states, let_yld_states, on='state', how='inner')\n",
    "let_merged = let_merged.rename(columns={'sum_x': 'Workers', 'sum_y': 'Yield'})\n",
    "let_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442fa4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped bar plot\n",
    "let_merged.plot(x=\"state\", y=[\"Workers\", \"Yield\"], kind=\"bar\", figsize=(16,10))\n",
    "plt.title('States with \"Lettuce\" Workers and Lettuce Yields, 2010-2020', fontsize=22)\n",
    "plt.xlabel('')\n",
    "plt.xticks(fontsize=16, rotation=360)\n",
    "plt.ylabel('Number of H-2A workers', fontsize=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(let_merged.Workers, let_merged.Yield)\n",
    "plt.title('States by \"Lettuce\" Workers and Lettuce Yields, 2010-2020', fontsize=22, label=)\n",
    "plt.xlabel('Number of H-2A workers', fontsize=16)\n",
    "plt.xticks(fontsize=16, rotation=360)\n",
    "plt.ylabel('Lettuce yield (cwt)', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce863834",
   "metadata": {},
   "source": [
    "### States with most potato H-2A workers vs states with most potato yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72727f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# States with most workers\n",
    "query_pot1 = '''\n",
    "SELECT DISTINCT employer_state,\n",
    "   SUM((workers_req::float)) OVER(PARTITION BY employer_state)\n",
    "FROM main\n",
    "WHERE job_title ILIKE '%%potato%%'\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_pot1)\n",
    "pot_wkr_states = pd.read_sql(query_pot1, con = engine)\n",
    "pot_wkr_states.rename(columns={'employer_state': 'state'}, inplace=True)\n",
    "pot_wkr_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55310259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# States with most yields\n",
    "query_pot2 = '''\n",
    "SELECT DISTINCT state,\n",
    "    SUM(value) OVER(PARTITION BY state)\n",
    "FROM cy\n",
    "WHERE commodity LIKE 'POTATOES'\n",
    "GROUP BY state, value\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_pot2)\n",
    "pot_yld_states = pd.read_sql(query_pot2, con = engine)\n",
    "pot_yld_states\n",
    "# States with most yields: Change states to two-letter abbreviations\n",
    "pot_yld_states['state'] = pot_yld_states['state'].map({'CALIFORNIA':'CA', 'WASHINGTON':'WA', 'TEXAS':'TX', 'OREGON':'OR', 'IDAHO':'ID', 'COLORADO':'CO',  'WISCONSIN':'WI', 'NEBRASKA':'NE', 'MINNESOTA':'MN', 'NORTH DAKOTA':'ND', 'FLORIDA':'FL', 'MICHIGAN':'MI', 'OTHER STATES':'OTHER', 'KANSAS':'KS', 'NEW JERSEY':'NJ', 'ILLINOIS':'IL', 'MAINE':'ME', 'MONTANA':'MT', 'MARYLAND':'MD', 'NEW YORK':'NY', 'ALASKA':'AK', 'MISSOURI':'MI', 'NORTH CAROLINA':'NC', 'VIRGINIA':'VA', 'PENNSYLVANIA':'PA', 'MASSACHUSETTS':'MA', 'OHIO':'OH', 'LOUISIANA':'LA', 'MISSISSIPPI':'MS', 'DELAWARE':'DE', 'RHODE ISLAND':'RI', 'NEVADA':'NV', 'ARIZONA':'AZ', 'ARKANSAS':'AR', 'ALABAMA':'AL', 'NEW MEXICO':'NM'})\n",
    "pot_yld_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a079e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inner join (sum_x is workers, sum_y is yield)\n",
    "pot_merged = pd.merge(pot_wkr_states, pot_yld_states, on='state', how='inner')\n",
    "pot_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2cdc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(pot_merged.sum_x, pot_merged.sum_y);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea67138",
   "metadata": {},
   "source": [
    "### States with most tobacco H-2A workers vs states with most tobacco yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States with most workers\n",
    "query_tob1 = '''\n",
    "SELECT DISTINCT employer_state,\n",
    "   SUM((workers_req::float)) OVER(PARTITION BY employer_state)\n",
    "FROM main\n",
    "WHERE job_title ILIKE '%%tobacco%%'\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_tob1)\n",
    "tob_wkr_states = pd.read_sql(query_tob1, con = engine)\n",
    "tob_wkr_states.rename(columns={'employer_state': 'state'}, inplace=True)\n",
    "tob_wkr_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6123671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# States with most yields\n",
    "query_tob2 = '''\n",
    "SELECT DISTINCT state,\n",
    "    SUM(value) OVER(PARTITION BY state)\n",
    "FROM cy\n",
    "WHERE commodity LIKE 'TOBACCO'\n",
    "GROUP BY state, value\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_tob2)\n",
    "tob_yld_states = pd.read_sql(query_tob2, con = engine)\n",
    "tob_yld_states\n",
    "tob_yld_states['state'] = tob_yld_states['state'].map({'TENNESSEE':'TN', 'VIRGINIA':'VA', 'PENNSYLVANIA':'PA', 'KENTUCKY':'KY', 'NORTH CAROLINA':'NC', 'GEORGIA':'GA', 'SOUTH CAROLINA':'SC', 'OTHER STATES':'OTHER', 'OHIO':'OH', 'MASSACHUSETTS':'MA', 'CONNECTICUT':'CT'})\n",
    "tob_yld_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfb458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join (sum_x is workers, sum_y is yield)\n",
    "tob_merged = pd.merge(tob_wkr_states, tob_yld_states, on='state', how='inner')\n",
    "tob_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b61148",
   "metadata": {},
   "source": [
    "### States with most tomato H-2A workers vs states with most tomato yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f0a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States with most workers\n",
    "query_tom1 = '''\n",
    "SELECT DISTINCT employer_state,\n",
    "   SUM((workers_req::float)) OVER(PARTITION BY employer_state)\n",
    "FROM main\n",
    "WHERE job_title ILIKE '%%tomato%%'\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_tom1)\n",
    "tom_wkr_states = pd.read_sql(query_tom1, con = engine)\n",
    "tom_wkr_states.rename(columns={'employer_state': 'state'}, inplace=True)\n",
    "tom_wkr_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# States with most yields\n",
    "query_tom2 = '''\n",
    "SELECT DISTINCT state,\n",
    "    SUM(value) OVER(PARTITION BY state)\n",
    "FROM cy\n",
    "WHERE commodity LIKE 'TOMATOES'\n",
    "GROUP BY state, value\n",
    "ORDER BY sum DESC;\n",
    "'''\n",
    "result = engine.execute(query_tom2)\n",
    "tom_yld_states = pd.read_sql(query_tom2, con = engine)\n",
    "tom_yld_states['state'] = tom_yld_states['state'].map({'CALIFORNIA':'CA', 'MICHIGAN':'MI', 'OHIO':'OH', 'TENNESSEE':'TN', 'INDIANA':'IN', 'NORTH CAROLINA':'NC', 'SOUTH CAROLINA':'SC', 'VIRGINIA':'VA', 'FLORIDA':'FL', 'NEW JERSEY':'NJ', 'ALABAMA':'AL', 'ARKANSAS':'AR', 'NEW YORK':'NY', 'PENNSYLVANIA':'PA', 'GEORGIA':'GA', 'OTHER STATES':'OTHER', 'TEXAS':'TX'})\n",
    "tom_yld_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join (sum_x is workers, sum_y is yield)\n",
    "tom_merged = pd.merge(tom_wkr_states, tom_yld_states, on='state', how='inner')\n",
    "tom_merged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
